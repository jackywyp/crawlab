api:
  address: "localhost:8000"
mongo:
  host: 192.168.77.128
  port: 27017
  db: crawlab_test
  username: ""
  password: ""
  authSource: "admin"
redis:
  address: 192.168.77.128
  password: "baosight"
  database: 1
  port: 6379
kafka:
  nodes:
    - "192.168.77.128:9092"
log:
  level: info
  path: "D:/develope/tmp/crawlab/logs"
  isDeletePeriodically: "N"
  deleteFrequency: "@hourly"
server:
  host: 0.0.0.0
  port: 8000
  master: "Y"
  secret: "crawlab"
  register:
    # mac地址/ip地址/hostname, 如果是ip，则需要手动指定IP
    type: "mac"
    ip: ""
  lang: # 安装语言环境, Y 为安装，N 为不安装
    python: "Y"
    node: "N"
    java: "N"
    dotnet: "N"
    php: "N"
spider:
  path: "D:/develope/spiders"
task:
  workers: 4
other:
  tmppath: "D:/develope/tmp/crawlab/tmp"
version: 0.4.10
setting:
  allowRegister: "N"
  enableTutorial: "N"
  runOnMaster: "Y"
  demoSpiders: "N"
  checkScrapy: "Y"
  autoInstall: "Y"
notification:
  mail:
    server: ''
    port: ''
    senderEmail: ''
    senderIdentity: ''
    smtp:
      user: ''
      password: ''